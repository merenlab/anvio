#!/usr/bin/env python
# -*- coding: utf-8

import os
import sys

import anvio
import anvio.utils as utils
import anvio.terminal as terminal
import anvio.filesnpaths as filesnpaths

import IlluminaUtils.lib.fastqlib as u

from anvio.errors import ConfigError, FilesNPathsError

__author__ = "Developers of anvi'o (see AUTHORS.txt)"
__copyright__ = "Copyleft 2015-2019, the Meren Lab (http://merenlab.org/)"
__credits__ = []
__license__ = "GPL 3.0"
__version__ = anvio.__version__
__maintainer__ = "A. Murat Eren"
__email__ = "a.murat.eren@gmail.com"
__provides__ = ["short-reads-fasta"]
__requires__ = ["samples-txt"]
__description__ = ("You provide this program with FASTQ files for one or more samples AND one or more short sequences, "
                   "and it collects reads from FASTQ files that matches to your sequences. This tool can be "
                   "most powerful if you want to collect all short reads from one or more metagenomes that are "
                   "downstream to a known sequence. Using the comprehensive output files you can analyze the "
                   "diversity of seuqences visually, manually, or using established strategies such as oligotyping.")


run = terminal.Run()
progress = terminal.Progress()
pp = terminal.pretty_print
P = terminal.pluralize


def main(args):
    A = lambda x: args.__dict__[x] if x in args.__dict__ else None
    samples_txt = A('samples_txt')
    primers_file_path = A('primer_sequences')
    output_directory_path = A('output_dir') or os.path.abspath('./MATCHING_SEQUENCES')
    min_remainder_length = A('min_remainder_length') or 60
    report_raw = A('report_raw')
    stop_after = A('stop_after')

    filesnpaths.check_output_directory(output_directory_path)

    filesnpaths.is_file_tab_delimited(samples_txt)
    filesnpaths.is_file_plain_text(primers_file_path)

    samples_dict = utils.get_samples_txt_file_as_dict(samples_txt, run=run)
    primers = [s.strip().upper() for s in open(primers_file_path).readlines() if s[0] != '#']

    run.info("Samples found", f"({len(samples_dict)}) {' '.join(samples_dict.keys())}")
    run.info("Match sequences found", f"({len(primers)}) {' '.join(primers)}")
    run.info('Min remainder length', min_remainder_length)
    run.info('Output directory', output_directory_path)
    run.info('Report raw', report_raw)
    if stop_after:
        run.info('Stop after', stop_after, mc='red')

    filesnpaths.gen_output_directory(output_directory_path)

    for sample_name in samples_dict:
        samples_dict[sample_name]['hits'] = {}

    primers_dict = {}
    for m in primers:
        primers_dict[m] = {'matching_sequences': {},
                           'primer_length': len(m),
                           'primer_sequence': m,
                           'primer_sequence_rc': utils.rev_comp(m)}

        for sample_name in samples_dict:
            samples_dict[sample_name]['hits'][m] = 0
            primers_dict[m]['matching_sequences'][sample_name] = []


    total_read_counter = 0
    total_hit_counter = 0
    progress.new("Tick tock")
    progress.update('...')
    sample_names = sorted(list(samples_dict.keys()))
    for i in range(0, len(sample_names)):
        sample_name = sample_names[i]

        read_counter = 0
        hit_counter = 0
        hit_in_rc = 0
        for pair in ['r1', 'r2']:
            input_fastq_file_path = samples_dict[sample_name][pair]
            input_fastq = u.FastQSource(input_fastq_file_path, compressed=input_fastq_file_path.endswith('.gz'))

            while input_fastq.next(raw=True) and (hit_counter < stop_after if stop_after else True):
                read_counter += 1

                if read_counter % 10000 == 0:
                    progress.update(f"{sample_name} ({i + 1} of {len(samples_dict)}) / {pair} / Reads: {pp(read_counter)} / Hits: {pp(hit_counter)} (in RC: {pp(hit_in_rc)})")

                found_in_RC = False

                for v in primers_dict.values():
                    seq = input_fastq.entry.sequence
                    pos = seq.find(v['primer_sequence'])

                    if pos < 0:
                        # it not in it. how about the the reverse complement of it?
                        if seq.find(v['primer_sequence_rc']) >= 0:
                            # aha. the reverse complement sequence that carries our match found.
                            # now we will reverse complement the long sequence and update the pos
                            # and will continue as if nothing happened
                            found_in_RC = True
                            hit_in_rc += 1
                            seq = utils.rev_comp(seq)
                            pos = seq.find(v['primer_sequence'])

                    if pos < 0:
                        continue

                    if len(seq[pos + v['primer_length']:]) < min_remainder_length:
                        continue

                    v['matching_sequences'][sample_name].append((pos, seq), )

                    hit_counter += 1

                    samples_dict[sample_name]['hits'][v['primer_sequence']] += 1

                    if anvio.DEBUG:
                        progress.end()
                        print("\n%s -- %s| %s [%s] %s" % (sample_name, 'RC ' if found_in_RC else '   ', seq[:pos], v['primer_sequence'], seq[pos+v['primer_length']:]))
                        progress.new("Tick tock")
                        progress.update(f"{sample_name} ({i + 1} of {len(samples_dict)}) / {pair} / Reads: {pp(read_counter)} / Hits: {pp(hit_counter)} (in RC: {pp(hit_in_rc)})")


        samples_dict[sample_name]['num_reads'] = read_counter

        total_read_counter += read_counter
        total_hit_counter += hit_counter


    progress.end()

    run.warning(None, header="HITS PER SAMPLE", lc='yellow')
    run.info('Summary', f"", nl_after=1)
    run.info_single(f"After processing {pp(total_read_counter)} reads in {P('sample', len(samples_dict))}, anvi'o found "
                    f"{P('hit', total_hit_counter)} for your {P('sequence', len(primers_dict), prefix_for_singular='only')} "
                    f"in the primer sequences file. What is shown below breaks these numbers down per sample because that's how "
                    f"anvi'o rolls (SAM: Shortest sequence after match; LAM: Longest sequence after match; ALAM: Average length after match).", nl_after=1)

    for sample_name in samples_dict:
        run.info(f"{sample_name}", f"{pp(samples_dict[sample_name]['num_reads'])} total reads", nl_before=1, lc="green", mc="green")
        for primer_sequence in primers_dict:
            matching_sequence_hits = primers_dict[primer_sequence]['matching_sequences'][sample_name]
            primer_length = primers_dict[primer_sequence]['primer_length']
            seq_lengths_after_match = [len(s[1][s[0]+primer_length:]) for s in matching_sequence_hits]

            run.info(f"    {primer_sequence}", f"{pp(samples_dict[sample_name]['hits'][primer_sequence])} hits / SAM: {min(seq_lengths_after_match)} / LAM: {max(seq_lengths_after_match)} / ALAM: {sum(seq_lengths_after_match) / len(primers_dict[primer_sequence]['matching_sequences']):.2f}")

    if not total_read_counter:
        run.info_single('No hits were found :/', mc='red', nl_before=1)
        sys.exit()

    progress.new("Generating the raw hits files")
    progress.update('...')
    for sample_name in samples_dict:
        for primer_sequence in primers_dict:
            matching_sequence_hits = primers_dict[primer_sequence]['matching_sequences'][sample_name]

            output_file_path = os.path.join(output_directory_path, '%s-%s-HITS.fa' % (sample_name, primer_sequence))
            with open(output_file_path, 'w') as output:
                counter = 1
                for hit in matching_sequence_hits:
                    output.write(f'>{sample_name}_{primer_sequence}_{counter:05d}\n{hit[1]}\n')
                    counter += 1
    progress.end()

    if report_raw:
        run.info_single(f"Output files for raw sequences are ready in {output_directory_path}")
        sys.exit()

    progress.new("Generating the fancy hits files")
    progress.update('...')
    for sample_name in samples_dict:
        for primer_sequence in primers_dict:
            trimmed_output_file_path = os.path.join(output_directory_path, '%s-%s-HITS-TRIMMED.fa' % (sample_name, primer_sequence))
            gapped_output_file_path = os.path.join(output_directory_path, '%s-%s-HITS-WITH-GAPS.fa' % (sample_name, primer_sequence))

            matching_sequence_hits = primers_dict[primer_sequence]['matching_sequences'][sample_name]
            primer_length = primers_dict[primer_sequence]['primer_length']
            seq_lengths_after_match = [len(s[1][s[0]+primer_length:]) for s in matching_sequence_hits]

            with open(trimmed_output_file_path, 'w') as trimmed, open(gapped_output_file_path, 'w') as gapped:
                max_seq_length = max(seq_lengths_after_match) + primer_length
                min_seq_length = min(seq_lengths_after_match) + primer_length
                counter = 1
                for hit in matching_sequence_hits:
                    sequence = hit[1][hit[0]:]

                    sequence = sequence + '-' * (max_seq_length - len(sequence))
                    gapped.write(f'>{sample_name}_{primer_sequence}_{counter:05d}\n{sequence}\n')

                    sequence = sequence[:min_seq_length]
                    trimmed.write(f'>{sample_name}_{primer_sequence}_{counter:05d}\n{sequence}\n')

                    counter += 1
    progress.end()

    run.info_single(f"All output files are ready in {output_directory_path}", nl_before=1, nl_after=1)


if __name__ == '__main__':
    from anvio.argparse import ArgumentParser
    parser = ArgumentParser(description=__description__)

    groupA = parser.add_argument_group('INPUT FILES', "Here you are expected to declare your FASTQ files and sequences "
                            "which you are interested to find in those FASTQ files. Each file should have at least one "
                            "entry")
    groupA.add_argument(*anvio.A('samples-txt'), **anvio.K('samples-txt'))
    groupA.add_argument('--primer-sequences', required=True, metavar='FILE', help="A single-column file that contains one "
                            "or more short sequences to be searhed.")

    groupB = parser.add_argument_group('PARAMETERS OF LIFE AND DEATH', "Here you are expected to set appropriate "
                            "paramters for your search (or you can choose to go with the defaults)")
    groupB.add_argument('-m', '--min-remainder-length', metavar='INT', type=int, default=60,
                        help="Minimum length of the remainder of the read after a match. If your short read "
                              "is XXXMMMMMMYYYYYYYYYYYYYY, where Ms indicate the primer sequence, "
                              "min remainder length is equal to the length of nucleotide matching Y. Default is %(default)d.")
    groupB.add_argument('--report-raw', action="store_true", help="Just report them sequences. Don't bother trimming.")
    groupB.add_argument('--stop-after', metavar='INT', type=int, default=0, help="Stop after X number of hits because "
                               "who needs data.")

    groupC = parser.add_argument_group('OUTPUT', "Tell anvi'o where to put your thingies")
    groupC.add_argument(*anvio.A('output-dir'), **anvio.K('output-dir'))

    args = parser.get_args(parser)

    try:
        main(args)
    except ConfigError as e:
        print(e)
        sys.exit(-1)
    except FilesNPathsError as e:
        print(e)
        sys.exit(-2)
