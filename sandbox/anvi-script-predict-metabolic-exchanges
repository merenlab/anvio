#!/usr/bin/env python
# -*- coding: utf-8

import sys
import anvio
import anvio.utils as utils
import anvio.kgml as kgml
import anvio.terminal as terminal
import anvio.reactionnetwork as rn
import anvio.kgmlnetworkops as nw

from copy import deepcopy
from argparse import Namespace
from collections import defaultdict

from anvio.dbops import ContigsDatabase
from anvio.errors import ConfigError, FilesNPathsError
from anvio.terminal import time_program

__copyright__ = "Copyleft 2015-2025, The Anvi'o Project (http://anvio.org/)"
__license__ = "GPL 3.0"
__version__ = anvio.__version__
__authors__ = ['ivagljiva']
__requires__ = ['contigs-db'] #TODO: add equivalent-compounds-txt as new artifact
__provides__ = []
__description__ = "Predicts metabolic exchanges between microbes based on the reaction network"

run = terminal.Run()
progress = terminal.Progress()

MAPS_TO_EXCLUDE = set(["00470", # D-amino acid biosynthesis. This map mostly connects other maps.
                       "00195", # Photosynthesis. This map describes photosystems and complexes rather than reactions.
                       "00190", # Oxidative Phosphorylation. This map describes enzyme complexes rather than reactions.
                       "00543", # Exopolysaccharide biosynthesis. Does not have a RN-type KGML file.
])

@time_program
def main(args):

    #input sanity checks
    if args.contigs_db_1 or args.contigs_db_2:
        if not args.contigs_db_2 or not args.contigs_db_1:
            raise ConfigError("You need two contigs databases for this to work.")
    if args.use_equivalent_amino_acids and args.custom_equivalent_compounds_file:
        raise ConfigError("You can only provide one of `--use-equivalent-amino-acids` and `--custom-equivalent-compounds-file`. If you "
                        "want to equate L- and non-stereo-specific amino acid IDs, you should include them in your custom equivalents file. "
                        "(Pro tip: the easiest way to do that is to run this program once with just `--use-equivalent-amino-acids` to get the "
                        "AA equivalents file, and modify from there)")

    eq_compounds = {}
    run.info("Using equivalent L- and non-stereo-specific amino acid compound IDs", args.use_equivalent_amino_acids)
    if args.use_equivalent_amino_acids:
        eq_compounds = find_equivalent_amino_acids(args)
    elif args.custom_equivalent_compounds_file:
        run.info("Custom equivalent compounds file", args.custom_equivalent_compounds_file)
        eq_compounds = utils.get_TAB_delimited_file_as_dictionary(args.custom_equivalent_compounds_file, expected_fields=['compound_id','equivalent_id'])
        # make sure each match is in there twice for easy lookups from either direction
        pairs_to_add = {}
        for c, match in eq_compounds.items():
            c2 = match['equivalent_id']
            if c2 not in eq_compounds:
                pairs_to_add[c2] = {'equivalent_id': c}
            elif eq_compounds[c2]['equivalent_id'] != c:
                raise ConfigError(f"While parsing your file of custom equivalent compound IDs, we found a pair of equivalents that don't match: "
                                    f"compound {c} is paired with {c2}, while {c2} is paired with {eq_compounds[c2]['equivalent_id']}. You should probably "
                                    f"fix that.")
        if pairs_to_add:
            eq_compounds.update(pairs_to_add)
            if anvio.DEBUG:
                run.warning(f"Found {len(pairs_to_add)} inverse pairs of equivalent compounds that were not in the equivalent compounds file. "
                                    f"These have been added to the dictionary of equivalent compounds. Here is the set of missing pairs: {pairs_to_add}. ",
                                    header="DEBUG", lc="yellow")

    run.info("Doing pathway walks for additional evidence", not args.no_pathway_walk)

    genomes_to_compare = {'A': {'contigs_db_path': args.contigs_db_1},
                          'B': {'contigs_db_path': args.contigs_db_2}}
    constructor = rn.Constructor()
    for g in genomes_to_compare:
        run.info("Loading reaction network from database", args.contigs_db_1)
        genomes_to_compare[g]['network'] = constructor.load_network(contigs_db=genomes_to_compare[g]['contigs_db_path'], quiet=True)
    merged, db_names = genomes_to_compare['A']['network']._merge_two_genome_networks(genomes_to_compare['B']['network'])
    genomes_to_compare['A']['name'] = db_names[0]
    genomes_to_compare['B']['name'] = db_names[1]
    run.info_single(f"Created a merged network with {len(merged.genes)} genes.")

    # set up some important data structures
    kegg_id_to_modelseed_id = map_kegg_ids_to_modelseed_ids(merged)
    kegg_id_to_compound_name = map_kegg_ids_to_compound_names(merged)
    all_pathway_maps = merged._get_pathway_map_set(map_ids_to_exclude=MAPS_TO_EXCLUDE, id_selection_prefix = "00")
    compound_to_pathway_walk_chains = defaultdict(dict) # we will fill this dict in as we process each compound
    """Dictionary structure: {compound_id (modelseed ID): {pathway_id: {organism_id: {fate: [chains]}}}}"""

    # a couple of helper functions that should probably eventually be class functions
    def get_compound_name_from_kegg_id(kid):
        if kid in kegg_id_to_compound_name:
            return kegg_id_to_compound_name[kid]
        else:
            return "None"

    def get_reaction_equation(reaction_value):
        name_list = [merged.metabolites[c].modelseed_name for c in reaction_value.compound_ids]
        return rn.get_chemical_equation(reaction_value, use_compound_names=name_list, ignore_compartments = True)

    # TODO multithread: split pathway maps between workers
    num_pms_to_process = len(all_pathway_maps)
    processed_count = 0
    progress.new('Walking through KEGG Pathway Maps', progress_total_items=num_pms_to_process)
    for pm in all_pathway_maps:
        for g in genomes_to_compare: 
            wargs = get_args_for_pathway_walker(genomes_to_compare[g]['network'], pm, fate='produce', gaps=args.maximum_gaps)
            walker = nw.KGMLNetworkWalker(wargs)
            production_chains = walker.get_chains()
            walker.compound_fate = 'consume'
            consumption_chains = walker.get_chains()
            for compound in set(production_chains.keys()).union(set(consumption_chains.keys())):
                if compound not in kegg_id_to_modelseed_id:
                    raise ConfigError(f"We didn't find a modelseed compound associated with {compound} in pathway map {pm}")
                modelseed_id = kegg_id_to_modelseed_id[compound]
                
                if pm not in compound_to_pathway_walk_chains[modelseed_id]:
                    compound_to_pathway_walk_chains[modelseed_id][pm] = {}
                compound_to_pathway_walk_chains[modelseed_id][pm][g] = {'produce': production_chains[compound] if compound in production_chains else None, 
                                                                           'consume': consumption_chains[compound] if compound in consumption_chains else None}
        processed_count += 1
        progress.update(f"{processed_count} / {num_pms_to_process} Pathway Maps")
        progress.increment(increment_to=processed_count)
    progress.end()
    compounds_not_in_maps = set(merged.metabolites.keys()).difference(set(compound_to_pathway_walk_chains.keys()))
    run.info("Number of Pathway Maps processed", len(all_pathway_maps))
    run.info("Number of compounds processed from Pathway Maps", len(compound_to_pathway_walk_chains.keys()))
    run.info("Number of compounds from merged network not in Pathway Maps", len(compounds_not_in_maps))
    
    # dictionaries to store output
    potentially_exchanged_compounds = {}
    unique_compounds = {}
    pathway_walk_evidence = {}
    pathway_walk_dict_key = 0
    processed_compound_ids = set() # this is how we'll make sure we don't process equivalent compounds twice
    num_compounds_to_process = len(compound_to_pathway_walk_chains)
    processed_count = 0
    progress.new('Processing compounds in KEGG Pathway Maps', progress_total_items=num_compounds_to_process)
    # TODO multithread: split compounds between workers
    for compound_id in compound_to_pathway_walk_chains:
        if compound_id in processed_compound_ids:
            continue
        compound_reaction_chains = {compound_id: compound_to_pathway_walk_chains[compound_id]}
        if compound_id in eq_compounds:
            eq_comp = eq_compounds[compound_id]['equivalent_id']
            if eq_comp in compound_to_pathway_walk_chains:
                compound_reaction_chains[eq_comp] = compound_to_pathway_walk_chains[eq_comp]
            processed_compound_ids.add(eq_comp)
        
        producer,consumer = predict_exchange_from_pathway_walk(compound_reaction_chains)
        if producer or consumer:
            compound_name = merged.metabolites[compound_id].modelseed_name
            producer_name = genomes_to_compare[producer]['name'] if producer else None
            consumer_name = genomes_to_compare[consumer]['name'] if consumer else None
            if producer == consumer or (not producer) or (not consumer): # unique to one genome
                unique_compounds[compound_id] = {'compound_name': compound_name, 
                                                 'genomes': ",".join([x for x in [producer_name,consumer_name] if x]),
                                                 'produced_by': producer_name,
                                                 'consumed_by': consumer_name,
                                                 'prediction_method': 'Pathway_Map_Walk',
                                                }
            else: # potentially-exchanged
                potentially_exchanged_compounds[compound_id] = {'compound_name': compound_name,
                                                                'genomes': ",".join([producer_name,consumer_name]),
                                                                'produced_by': producer_name,
                                                                'consumed_by': consumer_name,
                                                                'prediction_method': 'Pathway_Map_Walk',
                                                                }

                per_map_evidence_for_compound = get_pathway_walk_evidence(compound_reaction_chains, producer, consumer)
                overall_max_prior = None
                overall_max_posterior = None
                overall_overlap_prior = None # the overlaps will be set based on the longest chain of reactions prior/posterior
                overall_overlap_posterior = None
                prop_overlap_prior = None
                prop_overlap_posterior = None
                for map_id, map_evidence in per_map_evidence_for_compound.items():
                    pathway_walk_evidence[pathway_walk_dict_key] = {'compound': compound_id,
                                                                    'compound_name': compound_name,
                                                                    'type': "production",
                                                                    'organism': producer_name,
                                                                    'pathway_map': map_id,
                                                                    'longest_reaction_chain_length': map_evidence["max_production_length"],
                                                                    'maximum_overlap': map_evidence["max_production_overlap"],
                                                                    'proportion_overlap': map_evidence["prop_production_overlap"],
                                                                    'longest_chain_reactions': ",".join(map_evidence["longest_chain_producer_strings"]["reactions"]),
                                                                    'longest_chain_compounds': ",".join(map_evidence["longest_chain_producer_strings"]["compounds"]),
                                                                    'longest_chain_compound_names': ",".join([get_compound_name_from_kegg_id(c) for c in map_evidence["longest_chain_producer_strings"]["compounds"]])}
                    pathway_walk_dict_key += 1
                    pathway_walk_evidence[pathway_walk_dict_key] = {'compound': compound_id,
                                                                    'compound_name': compound_name,
                                                                    'type': "consumption",
                                                                    'organism': consumer_name,
                                                                    'pathway_map': map_id,
                                                                    'longest_reaction_chain_length': map_evidence["max_consumption_length"],
                                                                    'maximum_overlap': map_evidence["max_consumption_overlap"],
                                                                    'proportion_overlap': map_evidence["prop_consumption_overlap"],
                                                                    'longest_chain_reactions': ",".join(map_evidence["longest_chain_consumer_strings"]["reactions"]),
                                                                    'longest_chain_compounds': ",".join(map_evidence["longest_chain_consumer_strings"]["compounds"]),
                                                                    'longest_chain_compound_names': ",".join([get_compound_name_from_kegg_id(c) for c in map_evidence["longest_chain_consumer_strings"]["compounds"]])}
                    pathway_walk_dict_key += 1

                    # we want to find the longest chain of production reactions + the longest chain of consumption reactions
                    if (not overall_max_prior and map_evidence["max_production_length"]) or \
                        (overall_max_prior and map_evidence["max_production_length"] and overall_max_prior < map_evidence["max_production_length"]):
                        overall_max_prior = map_evidence["max_production_length"]
                        overall_overlap_prior = map_evidence["max_production_overlap"]
                        prop_overlap_prior = map_evidence["prop_production_overlap"]
                    if (not overall_max_posterior and map_evidence["max_consumption_length"]) or \
                        (overall_max_posterior and map_evidence["max_consumption_length"] and overall_max_posterior < map_evidence["max_consumption_length"]):
                        overall_max_posterior = map_evidence["max_consumption_length"]
                        overall_overlap_posterior = map_evidence["max_consumption_overlap"]
                        prop_overlap_posterior = map_evidence["prop_consumption_overlap"]

                longest_overall_chain = None
                if overall_max_prior and overall_max_posterior:
                    longest_overall_chain = overall_max_prior + overall_max_posterior
                elif overall_max_prior:
                    longest_overall_chain = overall_max_prior
                elif overall_max_posterior:
                    longest_overall_chain = overall_max_posterior
                potentially_exchanged_compounds[compound_id]['max_reaction_chain_length'] = longest_overall_chain
                potentially_exchanged_compounds[compound_id]['max_production_chain_length'] = overall_max_prior
                potentially_exchanged_compounds[compound_id]['max_consumption_chain_length'] = overall_max_posterior
                potentially_exchanged_compounds[compound_id]['production_overlap_length'] = overall_overlap_prior
                potentially_exchanged_compounds[compound_id]['consumption_overlap_length'] = overall_overlap_posterior
                potentially_exchanged_compounds[compound_id]['production_overlap_proportion'] = prop_overlap_prior
                potentially_exchanged_compounds[compound_id]['consumption_overlap_proportion'] = prop_overlap_posterior
        processed_compound_ids.add(compound_id)
        processed_count += 1
        progress.update(f"{processed_count} / {num_compounds_to_process} compounds processsed")
        progress.increment(increment_to=processed_count)

    progress.end()
    run.info("Number of exchanged compounds predicted from KEGG Pathway Map walks", len(potentially_exchanged_compounds))
    run.info("Number of unique compounds predicted from KEGG Pathway Map walks", len(unique_compounds))

     # loop over remaining metabolites (not in pathway maps)
    num_compounds_to_process = len(compounds_not_in_maps)
    unique_from_reaction_subset = 0 # a couple of counters to keep track of what this part of the code found
    exchange_from_reaction_subset = 0
    processed_count=0
    progress.new('Processing compounds in reaction network', progress_total_items=num_compounds_to_process)
    for compound_id in compounds_not_in_maps:
        if compound_id in processed_compound_ids:
            continue
        compound_name = merged.metabolites[compound_id].modelseed_name
        if anvio.DEBUG:
            progress.reset()
            run.info_single(f"Working on compound {compound_id} ({compound_name})")
        sub_ids = [compound_id]
        if compound_id in eq_compounds:
            eq_comp = eq_compounds[compound_id]['equivalent_id']
            sub_ids.append(eq_compounds[compound_id]['equivalent_id'])
            processed_compound_ids.add(eq_compounds[compound_id]['equivalent_id'])
        sub_network = merged.subset_network(metabolites_to_subset=sub_ids)

        genomes_produce = set([])
        genomes_consume = set([])
        production_reactions = {g: {} for g in genomes_to_compare}
        consumption_reactions = {g: {} for g in genomes_to_compare}
        for rid, reaction in sub_network.reactions.items():
            # replace all equivalent IDs with the compound ID we are currently working on in the network
            if compound_id in eq_compounds:
                eq_comp = eq_compounds[compound_id]['equivalent_id']
                reaction.compound_ids = [compound_id if x == eq_comp else x for x in reaction.compound_ids]

            idx = reaction.compound_ids.index(compound_id)
            #TODO: make a dict of compounds with transport reactions and use as evidence in final output
            if reaction.compound_ids.count(compound_id) > 1: # likely a transport reaction, ignore
                if anvio.DEBUG:
                    run.warning(f"Found {compound_id} more than once in {rid}. We are skipping this reaction",
                                    header="DEBUG", lc="yellow")
                continue
            # which genomes produce this compound?
            elif reaction.coefficients[idx] > 0:
                for g in genomes_to_compare:
                    if g in reaction.genomes_of_origin:
                        genomes_produce.add(g)
                        production_reactions[g][rid] = get_reaction_equation(reaction)

            # which genomes utilize this compound?
            elif reaction.coefficients[idx] < 0:
                for g in genomes_to_compare:
                    if g in reaction.genomes_of_origin:
                        genomes_consume.add(g)
                        consumption_reactions[g][rid] = get_reaction_equation(reaction)

        def add_reactions_to_dict_for_compound(compound_dict):
            """Modifies the compound dictionary in place to add production and consumption reaction output"""
            for g in genomes_to_compare:
                prod_rxn_ids = sorted(production_reactions[g].keys())
                cons_rxn_ids = sorted(consumption_reactions[g].keys())
                prod_rxn_eqs = [production_reactions[g][rid] for rid in prod_rxn_ids]
                cons_rxn_eqs = [consumption_reactions[g][rid] for rid in cons_rxn_ids]
                compound_dict[f"production_rxn_ids_{g}"] = " / ".join(prod_rxn_ids) if len(prod_rxn_ids) else None
                compound_dict[f"consumption_rxn_ids_{g}"] = " / ".join(cons_rxn_ids) if len(cons_rxn_ids) else None
                compound_dict[f"production_rxn_eqs_{g}"] = " / ".join(prod_rxn_eqs) if len(prod_rxn_eqs) else None
                compound_dict[f"consumption_rxn_eqs_{g}"] = " / ".join(cons_rxn_eqs) if len(cons_rxn_eqs) else None
        
        producer,consumer = producer_consumer_decision_tree(genomes_produce, genomes_consume)
        if producer or consumer:
            producer_name = genomes_to_compare[producer]['name'] if producer else None
            consumer_name = genomes_to_compare[consumer]['name'] if consumer else None
            if producer == consumer or (not producer) or (not consumer): # unique to one genome
                unique_compounds[compound_id] = {'compound_name': compound_name, 
                                                 'genomes': ",".join([x for x in [producer_name,consumer_name] if x]),
                                                 'produced_by': producer_name,
                                                 'consumed_by': consumer_name,
                                                 'prediction_method': 'Reaction_Network_Subset',
                                                }
                add_reactions_to_dict_for_compound(unique_compounds[compound_id])
                unique_from_reaction_subset+=1
            else: # potentially-exchanged
                potentially_exchanged_compounds[compound_id] = {'compound_name': compound_name,
                                                                'genomes': ",".join([producer_name,consumer_name]),
                                                                'produced_by': producer_name,
                                                                'consumed_by': consumer_name,
                                                                'prediction_method': 'Reaction_Network_Subset',
                                                                }
                add_reactions_to_dict_for_compound(potentially_exchanged_compounds[compound_id])
                exchange_from_reaction_subset+=1

        processed_compound_ids.add(compound_id)
        processed_count += 1
        progress.update(f"{processed_count} / {num_compounds_to_process} compounds processsed")
        progress.increment(increment_to=processed_count)

    progress.end()

    run.info("Number of exchanged compounds predicted from Reaction Network subset approach", exchange_from_reaction_subset)
    run.info("Number of unique compounds predicted from Reaction Network subset approach", unique_from_reaction_subset)
    run.warning(f"Identified {len(potentially_exchanged_compounds)} potentially exchanged compounds and {len(unique_compounds)} compounds unique to one genome.",
                header='OVERALL RESULTS', lc='green')

    output_header = ['compound_id', 'compound_name', 'genomes', 'produced_by', 'consumed_by', 'prediction_method']
    if args.add_reactions_to_output:
        output_header += [f"production_rxn_ids_{g}" for g in db_names] + [f"consumption_rxn_ids_{g}" for g in db_names] + \
        [f"production_rxn_eqs_{g}" for g in db_names] + [f"consumption_rxn_eqs_{g}" for g in db_names]
    exchange_header = deepcopy(output_header)
    if not args.no_pathway_walk:
        exchange_header += ['max_reaction_chain_length', 'max_production_chain_length', 'max_consumption_chain_length',
                            'production_overlap_length', 'consumption_overlap_length', 
                            'production_overlap_proportion', 'consumption_overlap_proportion']
    utils.store_dict_as_TAB_delimited_file(potentially_exchanged_compounds, f"{args.output_file_prefix}-potentially-exchanged-compounds.txt",
                key_header='compound_id', none_value="None", headers=exchange_header)
    utils.store_dict_as_TAB_delimited_file(unique_compounds, f"{args.output_file_prefix}-unique-compounds.txt",
                key_header='compound_id', none_value="None", headers=output_header)
    if not args.no_pathway_walk:
        utils.store_dict_as_TAB_delimited_file(pathway_walk_evidence, f"{args.output_file_prefix}-evidence.txt",
                    do_not_write_key_column=True, none_value="None")


def find_equivalent_amino_acids(args, run=run, progress=progress, print_to_file=True, output_file_name="equivalent_amino_acids.txt"):
    """Looks through the ModelSEED compound table to identify L-amino acids and their non-stereo-specific counterparts.

    Returns a dictionary in which keys are compound IDs matched to their names and the equivalent compound ID. Each match is
    in the dictionary twice to enable O(1) lookups with either compound ID.

    Parameters
    ==========
    print_to_file : Boolean
        if True, the dictionary of equivalent compounds will be written to a tab-delimited output file
    output_file_name : string
        the name of the output file to print to (if desired)
    """

    MS_db = rn.ModelSEEDDatabase(modelseed_dir=args.modelseed_data_dir)
    comps = MS_db.compounds_table.dropna(subset="name")

    aa_list = anvio.constants.amino_acids_long + ["Selenocysteine", "Pyrrolysine"]
    equivalent_AAs = {}
    for a in aa_list:
        eqs = comps[(comps.name == a) | (comps.name == f"L-{a}")]['name']
        id_list = eqs.index.to_list()
        if not len(id_list) == 2:
            if anvio.DEBUG:
                compound_list = [f"{i} ({comps.loc[i]})" for i in id_list]
                run.warning(f"While looking for equivalent compound IDs for the amino acid {a}, we didn't find the "
                            f"expected 2 matching compounds '{a}' and 'L-{a}'. Instead, here is what we found: "
                            f"{', '.join(compound_list)}. No equivalencies will be stored for this amino acid.", header='DEBUG', lc='yellow')
            continue
        equivalent_AAs[id_list[0]] = {'equivalent_id': id_list[1], 'name': eqs.loc[id_list[0]], 'equivalent_name': eqs.loc[id_list[1]]}
        equivalent_AAs[id_list[1]] = {'equivalent_id': id_list[0], 'name': eqs.loc[id_list[1]], 'equivalent_name': eqs.loc[id_list[0]]}

    if print_to_file:
        utils.store_dict_as_TAB_delimited_file(equivalent_AAs, output_file_name, key_header='compound_id',
                    headers = ['compound_id', 'equivalent_id', 'name', 'equivalent_name'])
        run.info("File of equivalent amino acid compound IDs", output_file_name)

    return equivalent_AAs

def map_kegg_ids_to_modelseed_ids(network):
    """Returns a dictionary where the keys are KEGG compound IDs and the values are ModelSEED IDs
    for all compounds in the provided network"""

    kegg_to_modelseed = {}
    for mid, compound in network.metabolites.items():
        for kid in compound.kegg_aliases:
            kegg_to_modelseed[kid] = mid
    return kegg_to_modelseed

def map_kegg_ids_to_compound_names(network):
    """Returns a dictionary where the keys are KEGG compound IDs and the values are compound names
    for all compounds in the provided network"""

    id_to_name_dict = {}
    for mid, compound in network.metabolites.items():
        for kid in compound.kegg_aliases:
            id_to_name_dict[kid] = compound.modelseed_name
    return id_to_name_dict

def get_args_for_pathway_walker(net, pathway_map, fate, gaps):
    """Returns a Namespace with arguments for KGMLNetworkWalker"""

    walker_args = Namespace()
    walker_args.network = net
    walker_args.kegg_pathway_number = pathway_map
    walker_args.compound_fate = fate
    walker_args.max_gaps = gaps
    walker_args.keep_intermediate_chains = True
    walker_args.verbose = False
    return walker_args

def walk_pathway_map_for_compound(compound_id, pathway_map_id, organism, compound_fate='produce'):
    """Walks a KEGG Pathway Map to identify reactions leading to a compound in an organism.

    Returns the reaction chains of either, (1) prior reactions that 'produce' a compound OR
    (2) posterior reactions that 'consume' a compound in the provided organism's reaction network.

    Parameters
    ==========
    compound_id : str
        The ModelSEED ID for the compound of interest
    pathway_map_id : str
        The KEGG Pathway Map to walk through. Should include this compound.
    organism : ReactionNetwork
        Loaded reaction network of the organism that can produce/consume this compound.
    compound_fate : str
        One of 'produce' or 'consume'. 'produce' is the default
    """

    try:
        wargs = get_args_for_pathway_walker(organism, pathway_map_id, compound_fate, args.maximum_gaps)
        walker = nw.KGMLNetworkWalker(wargs)
        reaction_chains = walker.get_chains(modelseed_compound_ids=compound_id)
        if not reaction_chains:
            return []
        return reaction_chains[compound_id]

    except ConfigError as c: # this is redundant for now, but useful for debugging
        print(f"Got ConfigError from pathway walker for {compound_id} in map {pathway_map_id}: {c}")
        return None
    except AssertionError as a:
        print(f"Got AssertionError from pathway walker for {compound_id} in map {pathway_map_id}: {a}")
        return None

def producer_consumer_decision_tree(genomes_can_produce, genomes_can_consume):
    """Given two genomes, decides which genome is the predicted producer/consumer of the current compound.
    If the compound is neither potentially-exchanged or unique to one genome, returns None so we can move on with our lives.
    """

    producer = None
    consumer = None
    if len(genomes_can_produce) == 1 or len(genomes_can_consume) == 1:
            # when the same genome produces and/or consumes, compound is unique to one genome
            if genomes_can_produce == genomes_can_consume:
                producer = genomes_can_produce.pop()
                consumer = genomes_can_consume.pop()
            elif len(genomes_can_produce) == 0: # only one can consume
                consumer = genomes_can_consume.pop()
            elif len(genomes_can_consume) == 0: # only one can produce
                producer = genomes_can_produce.pop()
            else: # potentially-exchanged
                if len(genomes_can_produce) == 2:
                    consumer = genomes_can_consume.pop()
                    genomes_can_produce.remove(consumer)
                    producer = genomes_can_produce.pop()
                elif len(genomes_can_consume) == 2:
                    producer = genomes_can_produce.pop()
                    genomes_can_consume.remove(producer)
                    consumer = genomes_can_consume.pop()
                else:
                    producer = genomes_can_produce.pop()
                    consumer = genomes_can_consume.pop()

    return producer, consumer

def predict_exchange_from_pathway_walk(chains_for_all_equivalent_compounds):
    """Determines whether a compound is unique or potentially-exchanged, and if so returns the internal IDs of 
    the producer/consumer genome (or None, otherwise). Only works for 2 genomes.
    """

    genomes_produce = set()
    genomes_consume = set()
    for cid, map_dict in chains_for_all_equivalent_compounds.items():
        for pm, genome_dict in map_dict.items():
            for g in genome_dict:
                if genome_dict[g]['produce']: # if this is not None, there is at least one production chain
                    genomes_produce.add(g)
                if genome_dict[g]['consume']: # if this is not None, there is at least one production chain
                    genomes_consume.add(g)

    prod, cons = producer_consumer_decision_tree(genomes_produce, genomes_consume)

    return prod, cons


def get_longest_chains(chain_list):
    max_length = None
    longest = []

    if chain_list:
        chain_lengths = [len(chain.kgml_reactions) for chain in chain_list]
        max_length = max(chain_lengths)
        longest = [chain_list[i] for i in range(len(chain_list)) if chain_lengths[i] == max_length]

    return max_length, longest

def get_max_overlap(starting_chains, comparison_chains):
    # below, we look for the longest reaction overlap between the longest producer chains and all consumer chains (or vice versa)
    # note that if there are multiple solutions with the same max overlap, we only report the first 'longest' chain with that overlap value
    max_overlap = None
    longest_with_max_overlap = None
    for sc in starting_chains:
        reaction_chain = [r.name for r in sc.kgml_reactions]
        for c in comparison_chains:
            compare_chain = [r.name for r in c.kgml_reactions]
            intersection = 0
            i = 0
            while (i < len(reaction_chain)) and (i < len(compare_chain)) and reaction_chain[i] == compare_chain[i]:
                intersection += 1
                i += 1
            if not max_overlap:
                max_overlap = intersection
                longest_with_max_overlap = sc
            elif intersection > max_overlap:
                max_overlap = intersection
                longest_with_max_overlap = sc

    return max_overlap, longest_with_max_overlap

def get_pathway_walk_evidence(compound, map_id, producer, consumer):
    """Calls the pathway walk in both organisms. Compares the output to compute max reaction chain length, overlap, etc"""

    production_chains_in_producer = walk_pathway_map_for_compound(compound, map_id, producer, 'produce')
    production_chains_in_consumer = walk_pathway_map_for_compound(compound, map_id, consumer, 'produce')
    consumption_chains_in_producer = walk_pathway_map_for_compound(compound, map_id, producer, 'consume')
    consumption_chains_in_consumer = walk_pathway_map_for_compound(compound, map_id, consumer, 'consume')

    max_production_length, longest_producer_chains = get_longest_chains(production_chains_in_producer)
    max_production_overlap, longest_with_max_overlap = get_max_overlap(longest_producer_chains, production_chains_in_consumer)

    if longest_with_max_overlap:
        longest_producer_chain_strings = {"reactions": [r.name for r in longest_with_max_overlap.kgml_reactions],
                                          "compounds": [c.name[4:] for c in longest_with_max_overlap.kgml_compound_entries]}
    else:
        longest_producer_chain_strings = {"reactions": [], "compounds": []}

    max_consumption_length, longest_consumer_chains = get_longest_chains(consumption_chains_in_consumer)
    max_consumption_overlap, longest_with_max_overlap = get_max_overlap(longest_consumer_chains, consumption_chains_in_producer)

    if longest_with_max_overlap:
        longest_consumer_chain_strings = {"reactions": [r.name for r in longest_with_max_overlap.kgml_reactions],
                                          "compounds": [c.name[4:] for c in longest_with_max_overlap.kgml_compound_entries]}
    else:
        longest_consumer_chain_strings = {"reactions": [], "compounds": []}

    results = {"max_production_length": max_production_length, # in producer network
               "max_consumption_length": max_consumption_length, # in consumer network
               "max_production_overlap": max_production_overlap, # between longest chain in producer network and all in consumer
               "max_consumption_overlap": max_consumption_overlap, # between longest chain in consumer network and all in producer
               "prop_production_overlap": max_production_overlap / max_production_length if max_production_length and max_production_overlap else None,
               "prop_consumption_overlap": max_consumption_overlap / max_consumption_length if max_consumption_length and max_consumption_overlap else None,
               "longest_chain_producer_strings": longest_producer_chain_strings,
               "longest_chain_consumer_strings": longest_consumer_chain_strings
    }

    return results


if __name__ == '__main__':
    from anvio.argparse import ArgumentParser

    parser = ArgumentParser(description=__description__)

    groupA = parser.add_argument_group('INPUT', "Just give us contigs databases that already had reaction networks generated "
                                                        "for them via `anvi-reaction-network`, and we will do the rest.")
    groupA.add_argument('-c1', '--contigs-db-1', required=True, help="Contigs database (generated by `anvi-gen-contigs-database`) for your first genome")
    groupA.add_argument('-c2', '--contigs-db-2', required=True, help="Contigs database (generated by `anvi-gen-contigs-database`) for your second genome")

    groupB = parser.add_argument_group('OUTPUT', "How do you want to see the results?")
    groupB.add_argument(*anvio.A('output-file-prefix'), **anvio.K('output-file-prefix', {'required': True}))

    groupC = parser.add_argument_group('METABOLISM DATA LOCATION', "What metabolism database(s) do you want to use?")
    groupC.add_argument(*anvio.A('kegg-data-dir'), **anvio.K('kegg-data-dir'))
    groupC.add_argument(*anvio.A('modelseed-data-dir'), **anvio.K('modelseed-data-dir'))

    groupD = parser.add_argument_group('CUSTOMIZATION', "Decisions only you can make.")
    groupD.add_argument(*anvio.A('use-equivalent-amino-acids'), **anvio.K('use-equivalent-amino-acids'))
    groupD.add_argument(*anvio.A('custom-equivalent-compounds-file'), **anvio.K('custom-equivalent-compounds-file'))
    groupD.add_argument('--maximum-gaps', required=False, type=int, metavar="INT", default=0, help="We'll look for the longest chain of reactions surrounding "
                                                        "each potentially-exchanged metabolite to help rank the output by "
                                                        "likelihood of the interaction. This parameter allows you to choose "
                                                        "how many gaps there can be in the chain on either side of the metabolite "
                                                        "in the network. Very conservatively set to 0, as in no gaps allowed.")
    groupD.add_argument('--add-reactions-to-output', required=False, action='store_true', help="Do you want relevant reaction IDs and chemical "
                                                        "equations to be added to the output? Use this flag.")

    groupE = parser.add_argument_group('PERFORMANCE', "Because ain't nobody got time for that")
    groupE.add_argument(*anvio.A('num-threads'), **anvio.K('num-threads'))
    groupE.add_argument('--no-pathway-walk', required=False, action='store_true', help="Skip walking KEGG pathways in the network upstream and downstream of "
                                                            "predicted exchanges for additional evidence to rank predictions (a time-consuming step).")

    args = parser.get_args(parser)

    try:
        main(args)
    except ConfigError as e:
        print(e)
        sys.exit(-1)
    except FilesNPathsError as e:
        print(e)
        sys.exit(-1)