#!/usr/bin/env python
# -*- coding: utf-8

import os
import sys
import random
import argparse

import anvio
import anvio.tables as t
import anvio.utils as utils
import anvio.terminal as terminal
import anvio.constants as constants
import anvio.clustering as clustering
import anvio.interactive as interactive
import anvio.filesnpaths as filesnpaths

from anvio.errors import ConfigError, FilesNPathsError


__copyright__ = "Copyleft 2015-2024, The Anvi'o Project (http://anvio.org/)"
__credits__ = ["Tom O. Delmont"]
__license__ = "GPL 3.0"
__version__ = anvio.__version__
__authors__ = ['meren']
__provides__ = ["interactive"]
__requires__ = ["variability-profile-txt"]
__resources__ = [("Use in the Infant Gut Tutorial", "http://merenlab.org/tutorials/infant-gut/#visualizing-snv-profiles-using-anvio")]
__description__ = "Take the output of anvi-gen-variability-profile, prepare an output for interactive interface"


run = terminal.Run()
progress = terminal.Progress()
pp = terminal.pretty_print


class AdHocRunGenerator:
    """From a matrix file to full-blown anvi'o interface.

       This is a class to take in a view data matrix at minimum, and create all
       necessary files for an anvi'o interactive interface call in manual mode."""

    def __init__(self, output_directory, view_data, additional_view_data, samples, skip_clustering_view_data=False, run=run, progress=progress, distance=None, linkage=None):
        self.run = run
        self.progress = progress

        self.view_data = view_data
        self.additional_view_data = additional_view_data
        self.samples = samples

        self.skip_clustering_view_data = skip_clustering_view_data
        self.delete_output_directory_if_exists = False

        # for clustering
        self.distance = distance or constants.distance_metric_default
        self.linkage = linkage or constants.distance_metric_default

        self.output_directory = output_directory


    def sanity_check(self):
        clustering.is_distance_and_linkage_compatible(self.distance, self.linkage)

        if os.path.exists(self.output_directory) and not self.delete_output_directory_if_exists:
            raise ConfigError("AdHocRunGenerator will not work with an existing directory. Please provide a new "
                               "path, or use the bool member 'delete_output_directory_if_exists' to overwrite "
                               "any existing directory.")

        filesnpaths.gen_output_directory(self.output_directory, delete_if_exists=self.delete_output_directory_if_exists)


    def get_output_file_path(self, file_name):
        return os.path.join(self.output_directory, file_name)


    def generate(self):
        self.sanity_check()

        # write view data
        view_data_path = self.get_output_file_path('view.txt')
        self.run.info("View data file", view_data_path)
        utils.store_dict_as_TAB_delimited_file(self.view_data, view_data_path, headers = ['contig'] + self.samples)

        # generate newick and write to file
        if not self.skip_clustering_view_data:
            tree_path = self.get_output_file_path('tree.txt')
            newick = clustering.get_newick_tree_data_for_dict(self.view_data, distance = self.distance, linkage=self.linkage)
            self.run.info("Tree file", tree_path)

            with open(tree_path, 'w') as f:
                f.write(newick)

        # create new profile.db and populate additional data
        profile_db_path = self.get_output_file_path('profile.db')
        self.run.info('Profile database', profile_db_path)

        args = argparse.Namespace()
        args.profile_db = profile_db_path
        args.manual_mode = True
        args.dry_run = True
        args.view_data = view_data_path
        args.tree = tree_path
        args.title = None
        interactive.Interactive(args)

        self.populate_additional_data(profile_db_path)

        self.run.info_single("Good news, your data is ready.", nl_before=1, mc='green')
        self.run.info_single("Please run 'anvi-interactive --manual -p %s --tree %s --view-data %s'" % (profile_db_path, tree_path, view_data_path), cut_after=200, nl_after=1, mc='green')


    def populate_additional_data(self, profile_db_path):
        table = t.miscdata.TableForItemAdditionalData(argparse.Namespace(profile_db=profile_db_path))
        table.add(self.additional_view_data, ['Competing NTs', 'Position in codon', 'Gene callers ID'], skip_check_names=True)

        table = t.miscdata.TableForLayerOrders(argparse.Namespace(profile_db=profile_db_path))
        layer_newick = clustering.get_newick_tree_data_for_dict(self.view_data, transpose=True, distance = self.distance, linkage=self.linkage)
        table.add({'default': {'data_type': 'newick', 'data_value': layer_newick}})

        # put a default state while you're at it
        t.states.TablesForStates(profile_db_path).store_state('default', '{"version": "3"}')


def main(args):
    filesnpaths.check_output_directory(args.output_dir)

    progress.new('Reading in your giant file')
    progress.update('...')
    profile = utils.get_TAB_delimited_file_as_dictionary(args.profile)
    progress.end()

    run.info('Num entries', pp(len(profile)))

    for field in [f for f in t.variable_nts_table_structure[1:] if f != 'split_name']:
        if field not in list(profile.values())[0]:
            raise ConfigError("The input file does not look like it is generated by anvi-gen-variability-profile. "
                               "It is missing at least one field that should have appeared in this file (%s)" % field)

    nt_positions = set(e['unique_pos_identifier'] for e in list(profile.values()))
    run.info('Num positions', pp(len(nt_positions)))

    if args.random:
        if args.random >= len(profile):
            run.info_single("You set a number to randomly subset your data, but it is larger than the actual number of "
                            "positions. So anvi'o will gracefully ignore that parameter.", nl_before=1, nl_after=1)
            args.random = None
        else:
            run.info('Random sampling', 'Unique positions will be subsampled to %s.' % pp(args.random))

    samples = sorted(list(set([e['sample_id'] for e in list(profile.values())])))
    run.info('Num samples', pp(len(samples)))

    run.warning(None, header="VERY IMPORTANT PARAMS", lc="green")
    run.info('Intergenic SNVs will be removed', 'Yes' if args.only_in_genes else 'No')
    run.info('Min departure from consensus', pp(args.min_departure_from_consensus))
    run.info('Max departure from consensus', pp(args.max_departure_from_consensus))
    run.info('Min departure from reference', pp(args.min_departure_from_reference))
    run.info('Max departure from reference', pp(args.max_departure_from_reference), nl_after=1)

    data_dict = {}
    additional_data_dict = {}
    removed_for_only_in_genes = 0
    removed_for_departure_from_consensus = 0
    removed_for_departure_from_reference = 0

    progress.new('Crunching data', progress_total_items=len(profile))
    progress.update('...')
    entry_count = 0
    for entry in list(profile.values()):
        entry_count += 1

        if entry_count % 500 == 0:
            progress.increment(increment_to=entry_count)
            progress.update("%s entries processed ..." % pp(entry_count))

        if args.only_in_genes and int(entry['corresponding_gene_call']) == -1:
            removed_for_only_in_genes += 1
            continue

        unique_pos_identifier = 'p_%08d' % (int(entry['unique_pos_identifier']))
        sample = entry['sample_id']
        departure_from_consensus = float(entry['departure_from_consensus'])
        departure_from_reference = float(entry['departure_from_reference'])

        if departure_from_consensus < args.min_departure_from_consensus or departure_from_consensus > args.max_departure_from_consensus:
            removed_for_departure_from_consensus += 1
            continue

        if departure_from_reference < args.min_departure_from_reference or departure_from_reference > args.max_departure_from_reference:
            removed_for_departure_from_reference += 1
            continue

        if unique_pos_identifier not in data_dict:
            data_dict[unique_pos_identifier] = dict(list(zip(samples, [0.0] * len(samples))))
            additional_data_dict[unique_pos_identifier] = {'Competing NTs': None, 'Position in codon': None}

        additional_data_dict[unique_pos_identifier]['Competing NTs'] = entry['competing_nts']

        if args.display_dep_from_reference:
            data_dict[unique_pos_identifier][sample] = departure_from_reference
        else:
            data_dict[unique_pos_identifier][sample] = departure_from_consensus

        # append 'st', 'nd', or 'th' to make categorical
        additional_data_dict[unique_pos_identifier]['Position in codon'] = utils.get_ordinal_from_integer(int(entry['base_pos_in_codon']))
        additional_data_dict[unique_pos_identifier]['Gene callers ID'] = int(entry['corresponding_gene_call']) if int(entry['corresponding_gene_call']) > -1 else 0

    progress.end()

    run.info("Num pos removed because they were not in genes", removed_for_only_in_genes, mc='red')
    run.info("Num pos removed due to min/max dep from reference", removed_for_departure_from_reference, mc='red')
    run.info("Num pos removed due to min/max dep from consensus", removed_for_departure_from_consensus, nl_after=1, mc='red')

    # figure out whether there are too many data points to work with
    unique_positions = list(data_dict.keys())

    if args.random:
        unique_positions_to_keep = set(random.sample(unique_positions, int(args.random)))
        progress.new('Selecting a random subset of unique positions')
        progress.update('...')

        for unique_position in unique_positions:
            if unique_position not in unique_positions_to_keep:
                data_dict.pop(unique_position)
                additional_data_dict.pop(unique_position)
            else:
                unique_positions_to_keep.remove(unique_position)

        progress.end()

    if len(data_dict) > 10000 and not args.just_do_it:
        raise ConfigError("There will be more than 10,000 positions with variability in your final data table. This "
                          "is a bit too much to display comfortably. You can change your min/max departure from "
                          "consensus/reference values, or you can ask anvi'o to randomly select a number of positions "
                          "from your data dictionary by using `--random` parameter. Alternatively you can use the flag "
                          "`--just-to-it` to not see this message and letting anvi'o to try to cluster these data for you.")
    if len(data_dict) > 10000 and args.just_do_it:
        run.warning("There are %d positions to cluster, and anvi'o will try to do it since you so nicely asked anvi'o to "
                    "just to it. Brace yourself (for a potentially never-ending clustering operation).")

    g = AdHocRunGenerator(args.output_dir, data_dict, additional_data_dict, samples, linkage='ward')
    g.generate()


if __name__ == '__main__':
    from anvio.argparse import ArgumentParser

    parser = ArgumentParser(description=__description__)

    parser.add_argument('profile', help='The output file generated by anvi-gen-variability-profile', metavar='VARIABILITY_PROFILE')
    parser.add_argument('--min-departure-from-consensus', type=float, default=0.00, metavar="FLOAT",
                        help="Minimum departure from consensus at a given variable nucleotide position. The default\
                        is %(default).2f.")
    parser.add_argument('--max-departure-from-consensus', type=float, default=1.00, metavar="FLOAT",
                        help="Maximum departure from consensus at a given variable nucleotide position. The default\
                        is %(default).2f.")
    parser.add_argument('--min-departure-from-reference', type=float, default=0.00, metavar="FLOAT",
                        help="Minimum departure from consensus at a given variable nucleotide position. The default\
                        is %(default).2f.")
    parser.add_argument('--max-departure-from-reference', type=float, default=1.00, metavar="FLOAT",
                        help="Maximum departure from consensus at a given variable nucleotide position. The default\
                        is %(default).2f.")
    parser.add_argument('--display-dep-from-reference', default=False, action="store_true",
                        help="By default this program will generate a matrix file that displays departure from consensus\
                        values. This flag will switch to departure from reference.")
    parser.add_argument('--only-in-genes', default=False, action="store_true",
                        help="With this flag you will ignore SNVs in non-coding regions.")
    parser.add_argument('--random', type=int, default=None, metavar="INTEGER",
                        help="Use this parameter to randomly subset your data. If there are too many SNV positions,\
                              this script may take forever to finish. You should *never* let it try to deal with more than\
                              25-30K points, but an ideal would be around 4-5 thousand.")
    parser.add_argument(*anvio.A('just-do-it'), **anvio.K('just-do-it'))
    parser.add_argument(*anvio.A('output-dir'), **anvio.K('output-dir', {'required': True}))

    args = parser.get_args(parser)

    try:
        main(args)
    except ConfigError as e:
        print(e)
        sys.exit(-1)
    except FilesNPathsError as e:
        print(e)
        sys.exit(-1)
