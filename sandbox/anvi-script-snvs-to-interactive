#!/usr/bin/env python
# -*- coding: utf-8

import sys
import random

import anvio
import anvio.tables as t
import anvio.utils as utils
import anvio.terminal as terminal
import anvio.interactive as interactive
import anvio.filesnpaths as filesnpaths

from anvio.errors import ConfigError, FilesNPathsError


__copyright__ = "Copyleft 2015-2024, The Anvi'o Project (http://anvio.org/)"
__credits__ = ["Tom O. Delmont"]
__license__ = "GPL 3.0"
__version__ = anvio.__version__
__authors__ = ['meren']
__provides__ = ["interactive"]
__requires__ = ["variability-profile-txt"]
__resources__ = [("Use in the Infant Gut Tutorial", "http://merenlab.org/tutorials/infant-gut/#visualizing-snv-profiles-using-anvio")]
__description__ = "Take the output of anvi-gen-variability-profile, prepare an output for interactive interface"


run = terminal.Run()
progress = terminal.Progress()
pp = terminal.pretty_print

def main(args):
    filesnpaths.check_output_directory(args.output_dir)

    progress.new('Reading in your giant file')
    progress.update('...')
    profile = utils.get_TAB_delimited_file_as_dictionary(args.profile)
    progress.end()

    run.info('Num entries', pp(len(profile)))

    for field in [f for f in t.variable_nts_table_structure[1:] if f != 'split_name']:
        if field not in list(profile.values())[0]:
            raise ConfigError("The input file does not look like it is generated by anvi-gen-variability-profile. "
                               "It is missing at least one field that should have appeared in this file (%s)" % field)

    nt_positions = set(e['unique_pos_identifier'] for e in list(profile.values()))
    run.info('Num positions', pp(len(nt_positions)))

    if args.random:
        if args.random >= len(profile):
            run.info_single("You set a number to randomly subset your data, but it is larger than the actual number of "
                            "positions. So anvi'o will gracefully ignore that parameter.", nl_before=1, nl_after=1)
            args.random = None
        else:
            run.info('Random sampling', 'Unique positions will be subsampled to %s.' % pp(args.random))

    samples = sorted(list(set([e['sample_id'] for e in list(profile.values())])))
    run.info('Num samples', pp(len(samples)))

    run.warning(None, header="VERY IMPORTANT PARAMS", lc="green")
    run.info('Intergenic SNVs will be removed', 'Yes' if args.only_in_genes else 'No')
    run.info('Min departure from consensus', pp(args.min_departure_from_consensus))
    run.info('Max departure from consensus', pp(args.max_departure_from_consensus))
    run.info('Min departure from reference', pp(args.min_departure_from_reference))
    run.info('Max departure from reference', pp(args.max_departure_from_reference), nl_after=1)

    data_dict = {}
    additional_data_dict = {}
    removed_for_only_in_genes = 0
    removed_for_departure_from_consensus = 0
    removed_for_departure_from_reference = 0

    progress.new('Crunching data', progress_total_items=len(profile))
    progress.update('...')
    entry_count = 0
    for entry in list(profile.values()):
        entry_count += 1

        if entry_count % 500 == 0:
            progress.increment(increment_to=entry_count)
            progress.update("%s entries processed ..." % pp(entry_count))

        if args.only_in_genes and int(entry['corresponding_gene_call']) == -1:
            removed_for_only_in_genes += 1
            continue

        unique_pos_identifier = 'p_%08d' % (int(entry['unique_pos_identifier']))
        sample = entry['sample_id']
        departure_from_consensus = float(entry['departure_from_consensus'])
        departure_from_reference = float(entry['departure_from_reference'])

        if departure_from_consensus < args.min_departure_from_consensus or departure_from_consensus > args.max_departure_from_consensus:
            removed_for_departure_from_consensus += 1
            continue

        if departure_from_reference < args.min_departure_from_reference or departure_from_reference > args.max_departure_from_reference:
            removed_for_departure_from_reference += 1
            continue

        if unique_pos_identifier not in data_dict:
            data_dict[unique_pos_identifier] = dict(list(zip(samples, [0.0] * len(samples))))
            additional_data_dict[unique_pos_identifier] = {'Competing NTs': None, 'Position in codon': None}

        additional_data_dict[unique_pos_identifier]['Competing NTs'] = entry['competing_nts']

        if args.display_dep_from_reference:
            data_dict[unique_pos_identifier][sample] = departure_from_reference
        else:
            data_dict[unique_pos_identifier][sample] = departure_from_consensus

        # append 'st', 'nd', or 'th' to make categorical
        additional_data_dict[unique_pos_identifier]['Position in codon'] = utils.get_ordinal_from_integer(int(entry['base_pos_in_codon']))
        additional_data_dict[unique_pos_identifier]['Gene callers ID'] = int(entry['corresponding_gene_call']) if int(entry['corresponding_gene_call']) > -1 else 0

    progress.end()

    run.info("Num pos removed because they were not in genes", removed_for_only_in_genes, mc='red')
    run.info("Num pos removed due to min/max dep from reference", removed_for_departure_from_reference, mc='red')
    run.info("Num pos removed due to min/max dep from consensus", removed_for_departure_from_consensus, nl_after=1, mc='red')

    # figure out whether there are too many data points to work with
    unique_positions = list(data_dict.keys())

    if args.random:
        unique_positions_to_keep = set(random.sample(unique_positions, int(args.random)))
        progress.new('Selecting a random subset of unique positions')
        progress.update('...')

        for unique_position in unique_positions:
            if unique_position not in unique_positions_to_keep:
                data_dict.pop(unique_position)
                additional_data_dict.pop(unique_position)
            else:
                unique_positions_to_keep.remove(unique_position)

        progress.end()

    if len(data_dict) > 10000 and not args.just_do_it:
        raise ConfigError("There will be more than 10,000 positions with variability in your final data table. This "
                          "is a bit too much to display comfortably. You can change your min/max departure from "
                          "consensus/reference values, or you can ask anvi'o to randomly select a number of positions "
                          "from your data dictionary by using `--random` parameter. Alternatively you can use the flag "
                          "`--just-do-it` to not see this message and letting anvi'o to try to cluster these data for you.")
    if len(data_dict) > 10000 and args.just_do_it:
        run.warning("There are %d positions to cluster, and anvi'o will try to do it since you so nicely asked anvi'o to "
                    "just to it. Brace yourself (for a potentially never-ending clustering operation).")

    g = interactive.AdHocRunGenerator(args.output_dir, data_dict, additional_data_dict, samples, linkage='ward')
    g.generate()


if __name__ == '__main__':
    from anvio.argparse import ArgumentParser

    parser = ArgumentParser(description=__description__)

    parser.add_argument('profile', help='The output file generated by anvi-gen-variability-profile', metavar='VARIABILITY_PROFILE')
    parser.add_argument('--min-departure-from-consensus', type=float, default=0.00, metavar="FLOAT",
                        help="Minimum departure from consensus at a given variable nucleotide position. The default\
                        is %(default).2f.")
    parser.add_argument('--max-departure-from-consensus', type=float, default=1.00, metavar="FLOAT",
                        help="Maximum departure from consensus at a given variable nucleotide position. The default\
                        is %(default).2f.")
    parser.add_argument('--min-departure-from-reference', type=float, default=0.00, metavar="FLOAT",
                        help="Minimum departure from consensus at a given variable nucleotide position. The default\
                        is %(default).2f.")
    parser.add_argument('--max-departure-from-reference', type=float, default=1.00, metavar="FLOAT",
                        help="Maximum departure from consensus at a given variable nucleotide position. The default\
                        is %(default).2f.")
    parser.add_argument('--display-dep-from-reference', default=False, action="store_true",
                        help="By default this program will generate a matrix file that displays departure from consensus\
                        values. This flag will switch to departure from reference.")
    parser.add_argument('--only-in-genes', default=False, action="store_true",
                        help="With this flag you will ignore SNVs in non-coding regions.")
    parser.add_argument('--random', type=int, default=None, metavar="INTEGER",
                        help="Use this parameter to randomly subset your data. If there are too many SNV positions,\
                              this script may take forever to finish. You should *never* let it try to deal with more than\
                              25-30K points, but an ideal would be around 4-5 thousand.")
    parser.add_argument(*anvio.A('just-do-it'), **anvio.K('just-do-it'))
    parser.add_argument(*anvio.A('output-dir'), **anvio.K('output-dir', {'required': True}))

    args = parser.get_args(parser)

    try:
        main(args)
    except ConfigError as e:
        print(e)
        sys.exit(-1)
    except FilesNPathsError as e:
        print(e)
        sys.exit(-1)
