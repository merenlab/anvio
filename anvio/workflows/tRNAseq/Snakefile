# -*- coding: utf-8

import anvio
import anvio.terminal as terminal
import anvio.db


__author__ = "Samuel Miller"
__copyright__ = "Copyright 2017, The anvio Project"
__credits__ = []
__license__ = "GPL 3.0"
__version__ = anvio.__version__
__maintainer__ = "Samuel Miller"
__email__ = "samuelmiller10@gmail.com"


import argparse
import anvio.workflows as w
import anvio.terminal as terminal
import anvio.utils as u

import os
import pandas as pd

from anvio.workflows.tRNAseq import tRNASeqWorkflow
from anvio.errors import ConfigError

run = terminal.Run()
progress = terminal.Progress()


M = tRNASeqWorkflow(argparse.Namespace(config=config))
M.init()
dirs_dict = M.dirs_dict


rule tRNAseq_workflow_target_rule:
    ''' The target rule for the workflow '''
    input: M.target_files


rule make_iu_input:
    ''' Create an Illumina-utils samples file from samples_txt (run once) '''

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "make_iu_input.log")
    # The input file is marked "ancient" to prevent Snakemake from rerunning this step
    # when the samples_txt file has been changed.
    input: ancient(M.get_param_value_from_config(['samples_txt']))
    output: os.path.join(dirs_dict['QC_DIR'], "iu_samples_input.txt")
    threads: M.T('make_iu_input')
    resources: nodes = M.T('make_iu_input')
    run:
        samples_txt_df = pd.read_csv(input[0], sep='\t', index_col=False)
        iu_samples_input_df = samples_txt_df[['r1', 'r2']] # r1 and r2 filepaths
        iu_samples_input_df['sample'] = samples_txt_df['sample'] + '_' + samples_txt_df['split'] # e.g., sample1_demethylase, sample1_untreated
        iu_samples_input_df[['sample', 'r1', 'r2']].to_csv(output[0], sep='\t', index=False) # reorder columns


rule iu_gen_configs:
    '''
    Create an Illumina-utils config file for each sample+split pair
    from the Illumina-utils samples file (run once)
    '''
    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "iu_gen_configs.log")
    # The input file is marked "ancient" to prevent Snakemake from rerunning this step
    # when the iu_samples_input file has been changed.
    input: ancient(os.path.join(dirs_dict["QC_DIR"], "iu_samples_input.txt"))
    output: expand(os.path.join(dirs_dict["QC_DIR"], "{sample_split_prefix}.ini"), sample_split_prefix=M.sample_split_prefixes)
    params:
        DIR = dirs_dict['QC_DIR'],
        r1_prefix = M.get_rule_param('iu_gen_configs', '--r1-prefix'), # regex-formatted adapter tag at the beginning of the forward read, e.g., "^...AAGT"
        r2_prefix = M.get_rule_param('iu_gen_configs', '--r2-prefix') # regex-formatted adapter tag at the beginning of the reverse read
    threads: M.T('iu_gen_configs')
    resources: nodes = M.T('iu_gen_configs')
    shell: "iu-gen-configs {input} -o {params.DIR} {params.r1_prefix} {params.r2_prefix} >> {log} 2>&1"


rule iu_merge_pairs:
    ''' Merge paired-end reads using Illumina-utils '''
    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "{sample_split_prefix}-iu_merge_pairs.log")
    input: os.path.join(dirs_dict["QC_DIR"], "{sample_split_prefix}.ini")
    output:
        merged = os.path.join(dirs_dict["QC_DIR"], "{sample_split_prefix}_MERGED"),
        merge_failed = os.path.join(dirs_dict["QC_DIR"], "{sample_split_prefix}_FAILED"),
        merge_failed_with_Ns = os.path.join(dirs_dict["QC_DIR"], "{sample_split_prefix}_FAILED_WITH_Ns"),
        stats = os.path.join(dirs_dict["QC_DIR"], "{sample_split_prefix}_STATS")
    params:
        marker_gene_stringent = M.get_rule_param('iu_merge_pairs', '--marker-gene-stringent'), # allows for both full and partial overlap of inserts, by default trimming trailing adapters following fully overlapping inserts
        max_num_mismatches = M.get_rule_param('iu_merge_pairs', '--max-num-mismatches'),
        report_r1_prefix = M.get_rule_param('iu_merge_pairs', '--report-r1-prefix'), # flag for reporting the actual sequence of an adapter tag at the beginning of the forward read, which should be specified in iu_gen_configs
        report_r2_prefix = M.get_rule_param('iu_merge_pairs', '--report-r2-prefix') # flag for reporting the actual sequence of an adapter tag at the beginning of the reverse read
    threads: M.T('iu_merge_pairs')
    resources: nodes = M.T('iu_merge_pairs')
    shell: "iu-merge-pairs {input} {params.marker_gene_stringent} {params.max_num_mismatches} {params.report_r1_prefix} {params.report_r2_prefix} --num-threads {threads} >> {log} 2>&1"


rule gen_qc_report:
    ''' Report all quality control statistics (run once) '''
    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "gen_qc_report.log")
    input: expand(os.path.join(dirs_dict['QC_DIR'], "{sample_split_prefix}_STATS"), sample_split_prefix=M.sample_split_prefixes)
    output: os.path.join(dirs_dict['QC_DIR'], "qc-report.txt")
    threads: M.T('gen_qc_report')
    resources: nodes = M.T('gen_qc_report')
    run:
        report_dict = {}
        headers = []
        for i, filename in enumerate(input):
            sample_split = os.path.basename(filename).split("_STATS")[0]
            report_dict[sample_split] = {}
            file_headers = []
            with open(filename) as f:
                firstline = True
                for line in f:
                    if line == '\n':
                        break
                    line_frags = line.rstrip().split(' ...')
                    header = line_frags[0]
                    file_headers.append(header)
                    number = line_frags[1].split('\t')[1]
                    report_dict[sample_split][header] = number
            if i == 0:
                headers = file_headers
            else:
                if file_headers != headers:
                    raise ConfigError("The difference in output headers between STATS files "
                                      "indicates an inconsistency in how files were processed by 'iu-merge-pairs'. "
                                      "These files, for example, have a difference between their headers: "
                                      "%s and %s" % (input[i], input[i - 1]))
        u.store_dict_as_TAB_delimited_file(report_dict, output[0], headers=['sample + split'] + headers)


rule anvi_reformat_fasta:
    ''' Reformat the FASTA file to have Anvi\'o-compliant deflines '''
    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "{sample_split_prefix}-reformat_fasta.log")
    input: rules.iu_merge_pairs.output.merged
    output:
        fasta = os.path.join(dirs_dict['QC_DIR'], "{sample_split_prefix}.fasta"),
        report = os.path.join(dirs_dict['QC_DIR'], "{sample_split_prefix}_REFORMAT_REPORT.txt")
    threads: M.T('anvi_reformat_fasta')
    resources: nodes = M.T('anvi_reformat_fasta')
    params:
        simplify_names = M.get_rule_param('anvi_reformat_fasta', '--simplify-names')
    shell: "anvi-script-reformat-fasta -o {output.fasta} {params.simplify_names} --report-file {output.report} {input} >> {log} 2>&1"


rule compress_merged_fasta:
    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "{sample_split_prefix}-compress_merged_fasta.log")
    input:
        merged = rules.iu_merge_pairs.output.merged,
        merge_failed = rules.iu_merge_pairs.output.merge_failed,
        merge_failed_with_Ns = rules.iu_merge_pairs.output.merge_failed_with_Ns,
        _ = rules.anvi_reformat_fasta.output.fasta
    output:
        merged_gz = os.path.join(dirs_dict['QC_DIR'], "{sample_split_prefix}_MERGED.gz"),
        merge_failed_gz = os.path.join(dirs_dict['QC_DIR'], "{sample_split_prefix}_FAILED.gz"),
        merge_failed_with_Ns_gz = os.path.join(dirs_dict['QC_DIR'], "{sample_split_prefix}_FAILED_WITH_Ns.gz")
    threads: M.T('compress_merged_fasta')
    resources: nodes = M.T('compress_merged_fasta')
    run:
        shell("gzip %s >> %s 2>&1" % (input.merged, log[0]))
        shell("gzip %s >> %s 2>&1" % (input.merge_failed, log[0]))
        shell("gzip %s >> %s 2>&1" % (input.merge_failed_with_Ns, log[0]))
        if rules.iu_merge_pairs.params.report_r1_prefix:
            shell("gzip %s >> %s 2>&1" % (os.path.join(dirs_dict['QC_DIR'], wildcards.sample_split_prefix + "_MERGED_R1_PREFIX"), log[0]))
        if rules.iu_merge_pairs.params.report_r2_prefix:
            shell("gzip %s >> %s 2>&1" % (os.path.join(dirs_dict['QC_DIR'], wildcards.sample_split_prefix + "_MERGED_R2_PREFIX"), log[0]))


rule anvi_gen_tRNAseq_database:
    ''' Identify tRNA sequences and their structural features, storing in an Anvi\'o database '''
    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "{sample_split_prefix}-anvi_gen_tRNAseq_database.log")
    input: rules.anvi_reformat_fasta.output.fasta
    output: os.path.join(dirs_dict['IDENT_DIR'], "{sample_split_prefix}_TRNASEQ.db")
    threads: M.T('anvi_gen_tRNAseq_database')
    resources: nodes = M.T('anvi_gen_tRNAseq_database')
    params:
        charging_recorded = M.get_rule_param('anvi_gen_tRNAseq_database', '--charging-recorded'), # tRNA-seq chemistry can record amino acid charging
        trust_fasta = M.get_rule_param('anvi_gen_tRNAseq_database', '--trust-fasta'), # save time by skipping basic FASTA format checks
        verbose = M.get_rule_param('anvi_gen_tRNAseq_database', '--verbose')
    shell: "anvi-gen-trnaseq-database -f {input} -o {output} {params.charging_recorded} {params.trust_fasta} -T {threads} {params.verbose}"


rule compress_reformatted_fasta:
    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "{sample_split_prefix}-compress_reformatted_fasta.log")
    input:
        fasta = rules.anvi_reformat_fasta.output.fasta,
        report = rules.anvi_reformat_fasta.output.report,
        _ = rules.anvi_gen_tRNAseq_database.output
    output: os.path.join(dirs_dict['QC_DIR'], "{sample_split_prefix}.fasta.gz")
    threads: M.T('compress_reformatted_fasta')
    resources: nodes = M.T('compress_reformatted_fasta')
    run:
        shell("gzip {input.fasta} >> {log} 2>&1" % (input.fasta, log[0]))
        shell("gzip {input.report} >> {log} 2>&1" % (input.report, log[0]))


rule get_unique_tRNA_fasta:
    ''' Recover a FASTA file of unique tRNA sequences '''
    # Remove the acceptor feature and any nucleotides 3' of the acceptor,
    # replacing with a uniform 3'-CCA acceptor.
    # A 3' sequence beside CCA is not biological but an artifact of the experiment.
    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "{sample_split_prefix}-get_unique_tRNA_fasta.log")
    input: rules.anvi_gen_tRNAseq_database.output
    output: os.path.join(dirs_dict['IDENT_DIR'], "{sample_split_prefix}_UNIQUE_TRNA.fasta")
    threads: M.T('get_unique_tRNA_fasta')
    resources: nodes = M.T('get_unique_tRNA_fasta')
    run:
        db = anvio.db.DB(input[0], '1')
        names = db.get_single_column_from_table('sequences', 'name')
        seqs = db.get_single_column_from_table('sequences', 'sequence')
        acceptor_starts = db.get_single_column_from_table('features', 'acceptor_start')
        seqs = [seq[: acceptor_start] + 'CCA' for seq, acceptor_start in zip(seqs, acceptor_starts)]
        with open(output[0], 'w') as outf:
            for name, seq in zip(names, seqs):
                outf.write(">%s\n" % name)
                outf.write("%s\n" % seq)


rule prefix_derep_tRNA_fasta:
    ''' Cluster fragmentary tRNA reads that are subsequences of other reads '''
    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "{sample_split_prefix}-prefix_derep_tRNA_seeds.log")
    input: rules.get_unique_tRNA_fasta.output
    output:
        fasta = os.path.join(dirs_dict['IDENT_DIR'], "{sample_split_prefix}_PREFIX_DEREP_TRNA.fasta"),
        uc = os.path.join(dirs_dict['IDENT_DIR'], "{sample_split_prefix}_UC_PREFIX_DEREP_TRNA.tsv")
    threads: M.T('prefix_derep_tRNA_fasta')
    resources: nodes = M.T('prefix_derep_tRNA_fasta')
    run:
        # All reads end in "CCA", so prefix dereplication should proceed from the 3' end.
        revcomp_filepath = os.path.join(dirs_dict['IDENT_DIR'], "%s_REVCOMP.fasta" % wildcards.sample_split_prefix)
        shell("vsearch --fastx_revcomp %s --fastaout %s --fasta_width 0 >> %s 2>&1" % (input[0], revcomp_filepath, log[0]))
        revcomp_prefix_derep_filepath = os.path.join(dirs_dict['IDENT_DIR'], "%s_REVCOMP_PREFIX_DEREP.fasta" % wildcards.sample_split_prefix)
        shell("vsearch --derep_prefix %s --output %s --uc %s --minseqlength 1 --fasta_width 0 --threads %d >> %s 2>&1" % (revcomp_filepath, revcomp_prefix_derep_filepath, output.uc, threads, log[0]))
        os.remove(revcomp_filepath)
        shell("vsearch --fastx_revcomp %s --fastaout %s --fasta_width 0 >> %s 2>&1" % (revcomp_prefix_derep_filepath, output.fasta, log[0]))
        os.remove(revcomp_prefix_derep_filepath)


rule map_tRNA:
    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "{sample_split_prefix}-map_tRNA.log")
    input: rules.prefix_derep_tRNA_fasta.output.fasta
    output:
        bam = os.path.join(dirs_dict['IDENT_DIR'], "{sample_split_prefix}.bam"),
        bam_index = os.path.join(dirs_dict['IDENT_DIR'], "{sample_split_prefix}.bam.bai")
    threads: M.T('map_tRNA')
    resources: nodes = M.T('map_tRNA')
    run:
        shell("bowtie2-build -f %s %s >> %s 2>&1" % (input[0], os.path.splitext(output.bam)[0], log[0]))
        sam_filepath = os.path.join(dirs_dict['IDENT_DIR'], "%s.sam" % wildcards.sample_split_prefix)
        # Use prohibitively high gap penalties to ensure reads can only map with a mismatch and not gap in the alignment.
        shell("bowtie2 -x %s -f %s -S %s --very-sensitive -N 1 -k 2 --rdg 100,3 --rfg 100,3 -p %d >> %s 2>&1" % (os.path.splitext(output.bam)[0], input[0], sam_filepath, threads, log[0]))
        raw_bam_filepath = os.path.splitext(output.bam)[0] + "_RAW.bam"
        shell("samtools view -bS %s -o %s -F 4 >> %s 2>&1" % (sam_filepath, raw_bam_filepath, log[0]))
        os.remove(sam_filepath)
        shell("anvi-init-bam %s -o %s -T %d >> %s 2>&1" % (raw_bam_filepath, output.bam, threads, log[0]))
        os.remove(raw_bam_filepath)


rule anvi_condense_clusters:
    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "{sample_split_prefix}-anvi_condense_clusters.log")
    input:
        bam = rules.map_tRNA.output.bam,
        trnaseqdb = rules.anvi_gen_tRNAseq_database.output
    output:
        bam = os.path.join(dirs_dict['IDENT_DIR'], "{sample_split_prefix}_CONDENSED.bam"),
        bam_index = os.path.join(dirs_dict['IDENT_DIR'], "{sample_split_prefix}_CONDENSED.bam.bai")
    threads: M.T('anvi-condense-clusters')
    resources: nodes = M.T('anvi_condense_clusters')
    shell: "anvi-condense-clusters {input.bam} {output.bam} {input.trnaseqdb} >> {log} 2>&1"


if 'workflows/tRNAseq' in workflow.included[0]:
    # check if all program dependencies are met. for this line to be effective,
    # there should be an initial dry run step (which is the default behavior of
    # the `WorkflowSuperClass`, so you are most likely covered).
    M.check_workflow_program_dependencies(workflow, dont_raise=True)